{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.31.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.31.0-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m473.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m914.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, outcome, webdriver-manager, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 selenium-4.31.0 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium webdriver-manager requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2025-04-04 21:28:13 - Starting download for category: tops\n",
      "[INFO] 2025-04-04 21:28:13 - Setting up Chrome WebDriver\n",
      "[INFO] 2025-04-04 21:28:13 - Installing ChromeDriver\n",
      "[INFO] 2025-04-04 21:28:15 - Chrome WebDriver setup complete\n",
      "[INFO] 2025-04-04 21:28:15 - Navigating to https://www.asos.com/us/women/tops/cat/?cid=4169\n",
      "[INFO] 2025-04-04 21:28:17 - Checking page load status\n",
      "[INFO] 2025-04-04 21:28:17 - Current URL: https://www.asos.com/us/women/tops/cat/?cid=4169\n",
      "[INFO] 2025-04-04 21:28:17 - Page title: Shop Women's Tops Online | ASOS\n",
      "[INFO] 2025-04-04 21:28:18 - Screenshot saved to /Users/lilysu/Documents/git/stylegap/asos_debug_screenshot.png\n",
      "[INFO] 2025-04-04 21:28:18 - Page source length: 697316 characters\n",
      "[INFO] 2025-04-04 21:28:18 - Body text preview: Skip to main content\n",
      "Help & FAQs\n",
      "WOMEN\n",
      "MEN\n",
      "Search\n",
      "TRENDING\n",
      "New in\n",
      "Clothing\n",
      "Dresses\n",
      "Shoes\n",
      "Plus size\n",
      "A...\n",
      "[INFO] 2025-04-04 21:28:18 - Waiting for initial page load\n",
      "[INFO] 2025-04-04 21:28:23 - Looking for product tiles\n",
      "[INFO] 2025-04-04 21:28:28 - Selector [data-auto-id='productTile'] not found\n",
      "[INFO] 2025-04-04 21:28:28 - Product tiles found with selector: article\n",
      "[INFO] 2025-04-04 21:28:28 - Checking for cookie consent banner\n",
      "[INFO] 2025-04-04 21:28:28 - Accepted cookies using selector: #onetrust-accept-btn-handler\n",
      "[INFO] 2025-04-04 21:28:30 - Processing page 1\n",
      "[INFO] 2025-04-04 21:28:33 - Found 72 products on page 1\n",
      "[INFO] 2025-04-04 21:28:34 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded: tops_0_.jpg\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded 1/50 images\n",
      "[INFO] 2025-04-04 21:28:34 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded: tops_1_.jpg\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded 2/50 images\n",
      "[INFO] 2025-04-04 21:28:34 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded: tops_2_.jpg\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded 3/50 images\n",
      "[INFO] 2025-04-04 21:28:34 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded: tops_3_.jpg\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded 4/50 images\n",
      "[INFO] 2025-04-04 21:28:34 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded: tops_4_.jpg\n",
      "[INFO] 2025-04-04 21:28:34 - Downloaded 5/50 images\n",
      "[INFO] 2025-04-04 21:28:34 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:35 - Downloaded: tops_5_.jpg\n",
      "[INFO] 2025-04-04 21:28:35 - Downloaded 6/50 images\n",
      "[INFO] 2025-04-04 21:28:35 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:35 - Downloaded: tops_6_.jpg\n",
      "[INFO] 2025-04-04 21:28:35 - Downloaded 7/50 images\n",
      "[INFO] 2025-04-04 21:28:35 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:35 - Downloaded: tops_7_.jpg\n",
      "[INFO] 2025-04-04 21:28:35 - Downloaded 8/50 images\n",
      "[INFO] 2025-04-04 21:28:35 - Looking for 'Load more' button\n",
      "[INFO] 2025-04-04 21:28:37 - Clicked 'Load more' button\n",
      "[INFO] 2025-04-04 21:28:42 - Processing page 2\n",
      "[INFO] 2025-04-04 21:28:45 - Found 144 products on page 2\n",
      "[INFO] 2025-04-04 21:28:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded: tops_8_.jpg\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded 9/50 images\n",
      "[INFO] 2025-04-04 21:28:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded: tops_9_.jpg\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded 10/50 images\n",
      "[INFO] 2025-04-04 21:28:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded: tops_10_.jpg\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded 11/50 images\n",
      "[INFO] 2025-04-04 21:28:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded: tops_11_.jpg\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded 12/50 images\n",
      "[INFO] 2025-04-04 21:28:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded: tops_12_.jpg\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded 13/50 images\n",
      "[INFO] 2025-04-04 21:28:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded: tops_13_.jpg\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded 14/50 images\n",
      "[INFO] 2025-04-04 21:28:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded: tops_14_.jpg\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded 15/50 images\n",
      "[INFO] 2025-04-04 21:28:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded: tops_15_.jpg\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded 16/50 images\n",
      "[INFO] 2025-04-04 21:28:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded: tops_16_.jpg\n",
      "[INFO] 2025-04-04 21:28:46 - Downloaded 17/50 images\n",
      "[INFO] 2025-04-04 21:28:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded: tops_17_.jpg\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded 18/50 images\n",
      "[INFO] 2025-04-04 21:28:47 - Downloading image from https://images.asos-media.com/products/4505-icon-s...\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded: tops_18_.jpg\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded 19/50 images\n",
      "[INFO] 2025-04-04 21:28:47 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded: tops_19_.jpg\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded 20/50 images\n",
      "[INFO] 2025-04-04 21:28:47 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded: tops_20_.jpg\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded 21/50 images\n",
      "[INFO] 2025-04-04 21:28:47 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded: tops_21_.jpg\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded 22/50 images\n",
      "[INFO] 2025-04-04 21:28:47 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded: tops_22_.jpg\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded 23/50 images\n",
      "[INFO] 2025-04-04 21:28:47 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:47 - Downloaded: tops_23_.jpg\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded 24/50 images\n",
      "[INFO] 2025-04-04 21:28:48 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded: tops_24_.jpg\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded 25/50 images\n",
      "[INFO] 2025-04-04 21:28:48 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded: tops_25_.jpg\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded 26/50 images\n",
      "[INFO] 2025-04-04 21:28:48 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded: tops_26_.jpg\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded 27/50 images\n",
      "[INFO] 2025-04-04 21:28:48 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded: tops_27_.jpg\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded 28/50 images\n",
      "[INFO] 2025-04-04 21:28:48 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded: tops_28_.jpg\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded 29/50 images\n",
      "[INFO] 2025-04-04 21:28:48 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded: tops_29_.jpg\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded 30/50 images\n",
      "[INFO] 2025-04-04 21:28:48 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded: tops_30_.jpg\n",
      "[INFO] 2025-04-04 21:28:48 - Downloaded 31/50 images\n",
      "[INFO] 2025-04-04 21:28:48 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded: tops_31_.jpg\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded 32/50 images\n",
      "[INFO] 2025-04-04 21:28:49 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded: tops_32_.jpg\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded 33/50 images\n",
      "[INFO] 2025-04-04 21:28:49 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded: tops_33_.jpg\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded 34/50 images\n",
      "[INFO] 2025-04-04 21:28:49 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded: tops_34_.jpg\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded 35/50 images\n",
      "[INFO] 2025-04-04 21:28:49 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded: tops_35_.jpg\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded 36/50 images\n",
      "[INFO] 2025-04-04 21:28:49 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded: tops_36_.jpg\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded 37/50 images\n",
      "[INFO] 2025-04-04 21:28:49 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded: tops_37_.jpg\n",
      "[INFO] 2025-04-04 21:28:49 - Downloaded 38/50 images\n",
      "[INFO] 2025-04-04 21:28:49 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded: tops_38_.jpg\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded 39/50 images\n",
      "[INFO] 2025-04-04 21:28:50 - Downloading image from https://images.asos-media.com/products/topshop-con...\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded: tops_39_.jpg\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded 40/50 images\n",
      "[INFO] 2025-04-04 21:28:50 - Downloading image from https://images.asos-media.com/products/weekday-hal...\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded: tops_40_.jpg\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded 41/50 images\n",
      "[INFO] 2025-04-04 21:28:50 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded: tops_41_.jpg\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded 42/50 images\n",
      "[INFO] 2025-04-04 21:28:50 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded: tops_42_.jpg\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded 43/50 images\n",
      "[INFO] 2025-04-04 21:28:50 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded: tops_43_.jpg\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded 44/50 images\n",
      "[INFO] 2025-04-04 21:28:50 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded: tops_44_.jpg\n",
      "[INFO] 2025-04-04 21:28:50 - Downloaded 45/50 images\n",
      "[INFO] 2025-04-04 21:28:50 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded: tops_45_.jpg\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded 46/50 images\n",
      "[INFO] 2025-04-04 21:28:51 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded: tops_46_.jpg\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded 47/50 images\n",
      "[INFO] 2025-04-04 21:28:51 - Downloading image from https://images.asos-media.com/products/asos-luxe-j...\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded: tops_47_.jpg\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded 48/50 images\n",
      "[INFO] 2025-04-04 21:28:51 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded: tops_48_.jpg\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded 49/50 images\n",
      "[INFO] 2025-04-04 21:28:51 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded: tops_49_.jpg\n",
      "[INFO] 2025-04-04 21:28:51 - Downloaded 50/50 images\n",
      "[INFO] 2025-04-04 21:28:51 - Reached maximum image count (50). Stopping.\n",
      "[INFO] 2025-04-04 21:28:51 - Closing Chrome WebDriver\n",
      "[INFO] 2025-04-04 21:28:51 - Completed download for category: tops\n",
      "[INFO] 2025-04-04 21:28:51 - Starting download for category: dresses\n",
      "[INFO] 2025-04-04 21:28:51 - Setting up Chrome WebDriver\n",
      "[INFO] 2025-04-04 21:28:51 - Installing ChromeDriver\n",
      "[INFO] 2025-04-04 21:28:54 - Chrome WebDriver setup complete\n",
      "[INFO] 2025-04-04 21:28:54 - Navigating to https://www.asos.com/us/women/dresses/cat/?cid=8799\n",
      "[INFO] 2025-04-04 21:28:57 - Checking page load status\n",
      "[INFO] 2025-04-04 21:28:57 - Current URL: https://www.asos.com/us/women/dresses/cat/?cid=8799\n",
      "[INFO] 2025-04-04 21:28:57 - Page title: Shop Women's Dresses for Every Occasion Online | ASOS\n",
      "[INFO] 2025-04-04 21:28:57 - Screenshot saved to /Users/lilysu/Documents/git/stylegap/asos_debug_screenshot.png\n",
      "[INFO] 2025-04-04 21:28:57 - Page source length: 582057 characters\n",
      "[INFO] 2025-04-04 21:28:57 - Body text preview: Skip to main content\n",
      "Help & FAQs\n",
      "WOMEN\n",
      "MEN\n",
      "Search\n",
      "TRENDING\n",
      "New in\n",
      "Clothing\n",
      "Dresses\n",
      "Shoes\n",
      "Plus size\n",
      "A...\n",
      "[INFO] 2025-04-04 21:28:57 - Waiting for initial page load\n",
      "[INFO] 2025-04-04 21:29:02 - Looking for product tiles\n",
      "[INFO] 2025-04-04 21:29:07 - Selector [data-auto-id='productTile'] not found\n",
      "[INFO] 2025-04-04 21:29:07 - Product tiles found with selector: article\n",
      "[INFO] 2025-04-04 21:29:07 - Checking for cookie consent banner\n",
      "[INFO] 2025-04-04 21:29:07 - Accepted cookies using selector: #onetrust-accept-btn-handler\n",
      "[INFO] 2025-04-04 21:29:09 - Processing page 1\n",
      "[INFO] 2025-04-04 21:29:12 - Found 72 products on page 1\n",
      "[INFO] 2025-04-04 21:29:12 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded: dresses_0_.jpg\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded 1/50 images\n",
      "[INFO] 2025-04-04 21:29:13 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded: dresses_1_.jpg\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded 2/50 images\n",
      "[INFO] 2025-04-04 21:29:13 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded: dresses_2_.jpg\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded 3/50 images\n",
      "[INFO] 2025-04-04 21:29:13 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded: dresses_3_.jpg\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded 4/50 images\n",
      "[INFO] 2025-04-04 21:29:13 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded: dresses_4_.jpg\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded 5/50 images\n",
      "[INFO] 2025-04-04 21:29:13 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded: dresses_5_.jpg\n",
      "[INFO] 2025-04-04 21:29:13 - Downloaded 6/50 images\n",
      "[INFO] 2025-04-04 21:29:13 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:29:14 - Downloaded: dresses_6_.jpg\n",
      "[INFO] 2025-04-04 21:29:14 - Downloaded 7/50 images\n",
      "[INFO] 2025-04-04 21:29:14 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:29:14 - Downloaded: dresses_7_.jpg\n",
      "[INFO] 2025-04-04 21:29:14 - Downloaded 8/50 images\n",
      "[INFO] 2025-04-04 21:29:17 - Looking for 'Load more' button\n",
      "[INFO] 2025-04-04 21:29:18 - No 'Load more' button found - we may have reached the end\n",
      "[INFO] 2025-04-04 21:29:18 - Total products downloaded: 8\n",
      "[INFO] 2025-04-04 21:29:18 - Closing Chrome WebDriver\n",
      "[INFO] 2025-04-04 21:29:18 - Completed download for category: dresses\n",
      "[INFO] 2025-04-04 21:29:18 - Starting download for category: jackets\n",
      "[INFO] 2025-04-04 21:29:18 - Setting up Chrome WebDriver\n",
      "[INFO] 2025-04-04 21:29:18 - Installing ChromeDriver\n",
      "[INFO] 2025-04-04 21:30:16 - Chrome WebDriver setup complete\n",
      "[INFO] 2025-04-04 21:30:16 - Navigating to https://www.asos.com/us/women/jackets-coats/cat/?cid=2641\n",
      "[INFO] 2025-04-04 21:30:26 - Checking page load status\n",
      "[INFO] 2025-04-04 21:30:26 - Current URL: https://www.asos.com/us/women/coats-jackets/cat/?cid=2641\n",
      "[INFO] 2025-04-04 21:30:26 - Page title: Shop Women's Coats & Jackets Online | ASOS\n",
      "[INFO] 2025-04-04 21:30:27 - Screenshot saved to /Users/lilysu/Documents/git/stylegap/asos_debug_screenshot.png\n",
      "[INFO] 2025-04-04 21:30:27 - Page source length: 682485 characters\n",
      "[INFO] 2025-04-04 21:30:27 - Body text preview: Skip to main content\n",
      "Help & FAQs\n",
      "WOMEN\n",
      "MEN\n",
      "Search\n",
      "TRENDING\n",
      "New in\n",
      "Clothing\n",
      "Dresses\n",
      "Shoes\n",
      "Plus size\n",
      "A...\n",
      "[INFO] 2025-04-04 21:30:27 - Waiting for initial page load\n",
      "[INFO] 2025-04-04 21:30:32 - Looking for product tiles\n",
      "[INFO] 2025-04-04 21:30:37 - Selector [data-auto-id='productTile'] not found\n",
      "[INFO] 2025-04-04 21:30:38 - Product tiles found with selector: article\n",
      "[INFO] 2025-04-04 21:30:38 - Checking for cookie consent banner\n",
      "[INFO] 2025-04-04 21:30:39 - Accepted cookies using selector: #onetrust-accept-btn-handler\n",
      "[INFO] 2025-04-04 21:30:41 - Processing page 1\n",
      "[INFO] 2025-04-04 21:30:44 - Found 72 products on page 1\n",
      "[INFO] 2025-04-04 21:30:45 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded: jackets_0_.jpg\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded 1/50 images\n",
      "[INFO] 2025-04-04 21:30:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded: jackets_1_.jpg\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded 2/50 images\n",
      "[INFO] 2025-04-04 21:30:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded: jackets_2_.jpg\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded 3/50 images\n",
      "[INFO] 2025-04-04 21:30:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded: jackets_3_.jpg\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded 4/50 images\n",
      "[INFO] 2025-04-04 21:30:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded: jackets_4_.jpg\n",
      "[INFO] 2025-04-04 21:30:45 - Downloaded 5/50 images\n",
      "[INFO] 2025-04-04 21:30:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:46 - Downloaded: jackets_5_.jpg\n",
      "[INFO] 2025-04-04 21:30:46 - Downloaded 6/50 images\n",
      "[INFO] 2025-04-04 21:30:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:46 - Downloaded: jackets_6_.jpg\n",
      "[INFO] 2025-04-04 21:30:46 - Downloaded 7/50 images\n",
      "[INFO] 2025-04-04 21:30:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:46 - Downloaded: jackets_7_.jpg\n",
      "[INFO] 2025-04-04 21:30:46 - Downloaded 8/50 images\n",
      "[INFO] 2025-04-04 21:30:46 - Looking for 'Load more' button\n",
      "[INFO] 2025-04-04 21:30:49 - Clicked 'Load more' button\n",
      "[INFO] 2025-04-04 21:30:54 - Processing page 2\n",
      "[INFO] 2025-04-04 21:30:57 - Found 144 products on page 2\n",
      "[INFO] 2025-04-04 21:30:57 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded: jackets_8_.jpg\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded 9/50 images\n",
      "[INFO] 2025-04-04 21:30:58 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded: jackets_9_.jpg\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded 10/50 images\n",
      "[INFO] 2025-04-04 21:30:58 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded: jackets_10_.jpg\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded 11/50 images\n",
      "[INFO] 2025-04-04 21:30:58 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded: jackets_11_.jpg\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded 12/50 images\n",
      "[INFO] 2025-04-04 21:30:58 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded: jackets_12_.jpg\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded 13/50 images\n",
      "[INFO] 2025-04-04 21:30:58 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded: jackets_13_.jpg\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded 14/50 images\n",
      "[INFO] 2025-04-04 21:30:58 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded: jackets_14_.jpg\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded 15/50 images\n",
      "[INFO] 2025-04-04 21:30:58 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded: jackets_15_.jpg\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded 16/50 images\n",
      "[INFO] 2025-04-04 21:30:58 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded: jackets_16_.jpg\n",
      "[INFO] 2025-04-04 21:30:58 - Downloaded 17/50 images\n",
      "[INFO] 2025-04-04 21:30:58 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded: jackets_17_.jpg\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded 18/50 images\n",
      "[INFO] 2025-04-04 21:30:59 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded: jackets_18_.jpg\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded 19/50 images\n",
      "[INFO] 2025-04-04 21:30:59 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded: jackets_19_.jpg\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded 20/50 images\n",
      "[INFO] 2025-04-04 21:30:59 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded: jackets_20_.jpg\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded 21/50 images\n",
      "[INFO] 2025-04-04 21:30:59 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded: jackets_21_.jpg\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded 22/50 images\n",
      "[INFO] 2025-04-04 21:30:59 - Downloading image from https://images.asos-media.com/products/the-north-f...\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded: jackets_22_.jpg\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded 23/50 images\n",
      "[INFO] 2025-04-04 21:30:59 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded: jackets_23_.jpg\n",
      "[INFO] 2025-04-04 21:30:59 - Downloaded 24/50 images\n",
      "[INFO] 2025-04-04 21:30:59 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded: jackets_24_.jpg\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded 25/50 images\n",
      "[INFO] 2025-04-04 21:31:00 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded: jackets_25_.jpg\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded 26/50 images\n",
      "[INFO] 2025-04-04 21:31:00 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded: jackets_26_.jpg\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded 27/50 images\n",
      "[INFO] 2025-04-04 21:31:00 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded: jackets_27_.jpg\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded 28/50 images\n",
      "[INFO] 2025-04-04 21:31:00 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded: jackets_28_.jpg\n",
      "[INFO] 2025-04-04 21:31:00 - Downloaded 29/50 images\n",
      "[INFO] 2025-04-04 21:31:00 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:01 - Downloaded: jackets_29_.jpg\n",
      "[INFO] 2025-04-04 21:31:01 - Downloaded 30/50 images\n",
      "[INFO] 2025-04-04 21:31:01 - Downloading image from https://images.asos-media.com/products/columbia-ha...\n",
      "[INFO] 2025-04-04 21:31:01 - Downloaded: jackets_30_.jpg\n",
      "[INFO] 2025-04-04 21:31:01 - Downloaded 31/50 images\n",
      "[INFO] 2025-04-04 21:31:01 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:02 - Downloaded: jackets_31_.jpg\n",
      "[INFO] 2025-04-04 21:31:02 - Downloaded 32/50 images\n",
      "[INFO] 2025-04-04 21:31:02 - Downloading image from https://images.asos-media.com/products/only-trench...\n",
      "[INFO] 2025-04-04 21:31:02 - Downloaded: jackets_32_.jpg\n",
      "[INFO] 2025-04-04 21:31:02 - Downloaded 33/50 images\n",
      "[INFO] 2025-04-04 21:31:02 - Downloading image from https://images.asos-media.com/products/river-islan...\n",
      "[INFO] 2025-04-04 21:31:02 - Downloaded: jackets_33_.jpg\n",
      "[INFO] 2025-04-04 21:31:02 - Downloaded 34/50 images\n",
      "[INFO] 2025-04-04 21:31:02 - Downloading image from https://images.asos-media.com/products/liquor-n-po...\n",
      "[INFO] 2025-04-04 21:31:03 - Downloaded: jackets_34_.jpg\n",
      "[INFO] 2025-04-04 21:31:03 - Downloaded 35/50 images\n",
      "[INFO] 2025-04-04 21:31:03 - Downloading image from https://images.asos-media.com/products/topshop-fau...\n",
      "[INFO] 2025-04-04 21:31:03 - Downloaded: jackets_35_.jpg\n",
      "[INFO] 2025-04-04 21:31:03 - Downloaded 36/50 images\n",
      "[INFO] 2025-04-04 21:31:03 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:03 - Downloaded: jackets_36_.jpg\n",
      "[INFO] 2025-04-04 21:31:03 - Downloaded 37/50 images\n",
      "[INFO] 2025-04-04 21:31:03 - Downloading image from https://images.asos-media.com/products/only-curve-...\n",
      "[INFO] 2025-04-04 21:31:04 - Downloaded: jackets_37_.jpg\n",
      "[INFO] 2025-04-04 21:31:04 - Downloaded 38/50 images\n",
      "[INFO] 2025-04-04 21:31:04 - Downloading image from https://images.asos-media.com/products/topshop-lon...\n",
      "[INFO] 2025-04-04 21:31:04 - Downloaded: jackets_38_.jpg\n",
      "[INFO] 2025-04-04 21:31:04 - Downloaded 39/50 images\n",
      "[INFO] 2025-04-04 21:31:04 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:04 - Downloaded: jackets_39_.jpg\n",
      "[INFO] 2025-04-04 21:31:04 - Downloaded 40/50 images\n",
      "[INFO] 2025-04-04 21:31:04 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:05 - Downloaded: jackets_40_.jpg\n",
      "[INFO] 2025-04-04 21:31:05 - Downloaded 41/50 images\n",
      "[INFO] 2025-04-04 21:31:05 - Downloading image from https://images.asos-media.com/products/topshop-twi...\n",
      "[INFO] 2025-04-04 21:31:05 - Downloaded: jackets_41_.jpg\n",
      "[INFO] 2025-04-04 21:31:05 - Downloaded 42/50 images\n",
      "[INFO] 2025-04-04 21:31:05 - Downloading image from https://images.asos-media.com/products/topshop-pat...\n",
      "[INFO] 2025-04-04 21:31:05 - Downloaded: jackets_42_.jpg\n",
      "[INFO] 2025-04-04 21:31:05 - Downloaded 43/50 images\n",
      "[INFO] 2025-04-04 21:31:06 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:06 - Downloaded: jackets_43_.jpg\n",
      "[INFO] 2025-04-04 21:31:06 - Downloaded 44/50 images\n",
      "[INFO] 2025-04-04 21:31:06 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:06 - Downloaded: jackets_44_.jpg\n",
      "[INFO] 2025-04-04 21:31:06 - Downloaded 45/50 images\n",
      "[INFO] 2025-04-04 21:31:06 - Downloading image from https://images.asos-media.com/products/river-islan...\n",
      "[INFO] 2025-04-04 21:31:06 - Downloaded: jackets_45_.jpg\n",
      "[INFO] 2025-04-04 21:31:06 - Downloaded 46/50 images\n",
      "[INFO] 2025-04-04 21:31:06 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:07 - Downloaded: jackets_46_.jpg\n",
      "[INFO] 2025-04-04 21:31:07 - Downloaded 47/50 images\n",
      "[INFO] 2025-04-04 21:31:07 - Downloading image from https://images.asos-media.com/products/the-north-f...\n",
      "[INFO] 2025-04-04 21:31:07 - Downloaded: jackets_47_.jpg\n",
      "[INFO] 2025-04-04 21:31:07 - Downloaded 48/50 images\n",
      "[INFO] 2025-04-04 21:31:07 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:07 - Downloaded: jackets_48_.jpg\n",
      "[INFO] 2025-04-04 21:31:07 - Downloaded 49/50 images\n",
      "[INFO] 2025-04-04 21:31:07 - Downloading image from https://images.asos-media.com/products/miss-selfri...\n",
      "[INFO] 2025-04-04 21:31:07 - Downloaded: jackets_49_.jpg\n",
      "[INFO] 2025-04-04 21:31:07 - Downloaded 50/50 images\n",
      "[INFO] 2025-04-04 21:31:07 - Reached maximum image count (50). Stopping.\n",
      "[INFO] 2025-04-04 21:31:07 - Closing Chrome WebDriver\n",
      "[INFO] 2025-04-04 21:31:07 - Completed download for category: jackets\n",
      "[INFO] 2025-04-04 21:31:07 - Starting download for category: shoes\n",
      "[INFO] 2025-04-04 21:31:07 - Setting up Chrome WebDriver\n",
      "[INFO] 2025-04-04 21:31:07 - Installing ChromeDriver\n",
      "[INFO] 2025-04-04 21:31:10 - Chrome WebDriver setup complete\n",
      "[INFO] 2025-04-04 21:31:10 - Navigating to https://www.asos.com/us/women/shoes/cat/?cid=4172\n",
      "[INFO] 2025-04-04 21:31:14 - Checking page load status\n",
      "[INFO] 2025-04-04 21:31:14 - Current URL: https://www.asos.com/us/women/shoes/cat/?cid=4172\n",
      "[INFO] 2025-04-04 21:31:14 - Page title: Shop Women's Shoes & Footwear Online | ASOS\n",
      "[INFO] 2025-04-04 21:31:14 - Screenshot saved to /Users/lilysu/Documents/git/stylegap/asos_debug_screenshot.png\n",
      "[INFO] 2025-04-04 21:31:14 - Page source length: 694575 characters\n",
      "[WARNING] 2025-04-04 21:31:14 - Possible bot detection on the page!\n",
      "[INFO] 2025-04-04 21:31:14 - Body text preview: Skip to main content\n",
      "Help & FAQs\n",
      "WOMEN\n",
      "MEN\n",
      "Search\n",
      "TRENDING\n",
      "New in\n",
      "Clothing\n",
      "Dresses\n",
      "Shoes\n",
      "Plus size\n",
      "A...\n",
      "[INFO] 2025-04-04 21:31:14 - Waiting for initial page load\n",
      "[INFO] 2025-04-04 21:31:19 - Looking for product tiles\n",
      "[INFO] 2025-04-04 21:31:25 - Selector [data-auto-id='productTile'] not found\n",
      "[INFO] 2025-04-04 21:31:25 - Product tiles found with selector: article\n",
      "[INFO] 2025-04-04 21:31:25 - Checking for cookie consent banner\n",
      "[INFO] 2025-04-04 21:31:25 - Accepted cookies using selector: #onetrust-accept-btn-handler\n",
      "[INFO] 2025-04-04 21:31:27 - Processing page 1\n",
      "[INFO] 2025-04-04 21:31:30 - Found 72 products on page 1\n",
      "[INFO] 2025-04-04 21:31:30 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:31:30 - Downloaded: shoes_0_.jpg\n",
      "[INFO] 2025-04-04 21:31:30 - Downloaded 1/50 images\n",
      "[INFO] 2025-04-04 21:31:30 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:31:30 - Downloaded: shoes_1_.jpg\n",
      "[INFO] 2025-04-04 21:31:30 - Downloaded 2/50 images\n",
      "[INFO] 2025-04-04 21:31:30 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:30 - Downloaded: shoes_2_.jpg\n",
      "[INFO] 2025-04-04 21:31:30 - Downloaded 3/50 images\n",
      "[INFO] 2025-04-04 21:31:30 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:30 - Downloaded: shoes_3_.jpg\n",
      "[INFO] 2025-04-04 21:31:30 - Downloaded 4/50 images\n",
      "[INFO] 2025-04-04 21:31:30 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:31 - Downloaded: shoes_4_.jpg\n",
      "[INFO] 2025-04-04 21:31:31 - Downloaded 5/50 images\n",
      "[INFO] 2025-04-04 21:31:31 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:31:31 - Downloaded: shoes_5_.jpg\n",
      "[INFO] 2025-04-04 21:31:31 - Downloaded 6/50 images\n",
      "[INFO] 2025-04-04 21:31:31 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:31 - Downloaded: shoes_6_.jpg\n",
      "[INFO] 2025-04-04 21:31:31 - Downloaded 7/50 images\n",
      "[INFO] 2025-04-04 21:31:31 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:31:31 - Downloaded: shoes_7_.jpg\n",
      "[INFO] 2025-04-04 21:31:31 - Downloaded 8/50 images\n",
      "[INFO] 2025-04-04 21:31:31 - Looking for 'Load more' button\n",
      "[INFO] 2025-04-04 21:31:34 - Clicked 'Load more' button\n",
      "[INFO] 2025-04-04 21:31:39 - Processing page 2\n",
      "[INFO] 2025-04-04 21:31:42 - Found 144 products on page 2\n",
      "[INFO] 2025-04-04 21:31:42 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded: shoes_8_.jpg\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded 9/50 images\n",
      "[INFO] 2025-04-04 21:31:42 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded: shoes_9_.jpg\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded 10/50 images\n",
      "[INFO] 2025-04-04 21:31:42 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded: shoes_10_.jpg\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded 11/50 images\n",
      "[INFO] 2025-04-04 21:31:42 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded: shoes_11_.jpg\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded 12/50 images\n",
      "[INFO] 2025-04-04 21:31:42 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded: shoes_12_.jpg\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded 13/50 images\n",
      "[INFO] 2025-04-04 21:31:42 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded: shoes_13_.jpg\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded 14/50 images\n",
      "[INFO] 2025-04-04 21:31:42 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded: shoes_14_.jpg\n",
      "[INFO] 2025-04-04 21:31:42 - Downloaded 15/50 images\n",
      "[INFO] 2025-04-04 21:31:42 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded: shoes_15_.jpg\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded 16/50 images\n",
      "[INFO] 2025-04-04 21:31:43 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded: shoes_16_.jpg\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded 17/50 images\n",
      "[INFO] 2025-04-04 21:31:43 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded: shoes_17_.jpg\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded 18/50 images\n",
      "[INFO] 2025-04-04 21:31:43 - Downloading image from https://images.asos-media.com/products/new-balance...\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded: shoes_18_.jpg\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded 19/50 images\n",
      "[INFO] 2025-04-04 21:31:43 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded: shoes_19_.jpg\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded 20/50 images\n",
      "[INFO] 2025-04-04 21:31:43 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded: shoes_20_.jpg\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded 21/50 images\n",
      "[INFO] 2025-04-04 21:31:43 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded: shoes_21_.jpg\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded 22/50 images\n",
      "[INFO] 2025-04-04 21:31:43 - Downloading image from https://images.asos-media.com/products/stradivariu...\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded: shoes_22_.jpg\n",
      "[INFO] 2025-04-04 21:31:43 - Downloaded 23/50 images\n",
      "[INFO] 2025-04-04 21:31:43 - Downloading image from https://images.asos-media.com/products/bershka-kne...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_23_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 24/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_24_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 25/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_25_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 26/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/simmi-londo...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_26_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 27/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/topshop-nat...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_27_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 28/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_28_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 29/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_29_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 30/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/arrange-pre...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_30_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 31/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_31_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 32/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded: shoes_32_.jpg\n",
      "[INFO] 2025-04-04 21:31:44 - Downloaded 33/50 images\n",
      "[INFO] 2025-04-04 21:31:44 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded: shoes_33_.jpg\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded 34/50 images\n",
      "[INFO] 2025-04-04 21:31:45 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded: shoes_34_.jpg\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded 35/50 images\n",
      "[INFO] 2025-04-04 21:31:45 - Downloading image from https://images.asos-media.com/products/adidas-orig...\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded: shoes_35_.jpg\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded 36/50 images\n",
      "[INFO] 2025-04-04 21:31:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded: shoes_36_.jpg\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded 37/50 images\n",
      "[INFO] 2025-04-04 21:31:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded: shoes_37_.jpg\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded 38/50 images\n",
      "[INFO] 2025-04-04 21:31:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded: shoes_38_.jpg\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded 39/50 images\n",
      "[INFO] 2025-04-04 21:31:45 - Downloading image from https://images.asos-media.com/products/schuh-laven...\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded: shoes_39_.jpg\n",
      "[INFO] 2025-04-04 21:31:45 - Downloaded 40/50 images\n",
      "[INFO] 2025-04-04 21:31:45 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded: shoes_40_.jpg\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded 41/50 images\n",
      "[INFO] 2025-04-04 21:31:46 - Downloading image from https://images.asos-media.com/products/raid-lanah-...\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded: shoes_41_.jpg\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded 42/50 images\n",
      "[INFO] 2025-04-04 21:31:46 - Downloading image from https://images.asos-media.com/products/azalea-wang...\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded: shoes_42_.jpg\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded 43/50 images\n",
      "[INFO] 2025-04-04 21:31:46 - Downloading image from https://images.asos-media.com/products/crocs-asos-...\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded: shoes_43_.jpg\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded 44/50 images\n",
      "[INFO] 2025-04-04 21:31:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded: shoes_44_.jpg\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded 45/50 images\n",
      "[INFO] 2025-04-04 21:31:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded: shoes_45_.jpg\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded 46/50 images\n",
      "[INFO] 2025-04-04 21:31:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded: shoes_46_.jpg\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded 47/50 images\n",
      "[INFO] 2025-04-04 21:31:46 - Downloading image from https://images.asos-media.com/products/asos-design...\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded: shoes_47_.jpg\n",
      "[INFO] 2025-04-04 21:31:46 - Downloaded 48/50 images\n",
      "[INFO] 2025-04-04 21:31:46 - Downloading image from https://images.asos-media.com/products/public-desi...\n",
      "[INFO] 2025-04-04 21:31:47 - Downloaded: shoes_48_.jpg\n",
      "[INFO] 2025-04-04 21:31:47 - Downloaded 49/50 images\n",
      "[INFO] 2025-04-04 21:31:47 - Downloading image from https://images.asos-media.com/products/glamorous-s...\n",
      "[INFO] 2025-04-04 21:31:47 - Downloaded: shoes_49_.jpg\n",
      "[INFO] 2025-04-04 21:31:47 - Downloaded 50/50 images\n",
      "[INFO] 2025-04-04 21:31:47 - Reached maximum image count (50). Stopping.\n",
      "[INFO] 2025-04-04 21:31:47 - Closing Chrome WebDriver\n",
      "[INFO] 2025-04-04 21:31:47 - Completed download for category: shoes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import urllib.parse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import traceback\n",
    "\n",
    "def print_debug(message, level=\"INFO\"):\n",
    "    \"\"\"Print debug message with timestamp and level for better tracking.\"\"\"\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{level}] {timestamp} - {message}\")\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Set up and return a Chrome webdriver with detailed logging.\"\"\"\n",
    "    print_debug(\"Setting up Chrome WebDriver\")\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    \n",
    "    try:\n",
    "        print_debug(\"Installing ChromeDriver\")\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        print_debug(\"Chrome WebDriver setup complete\")\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print_debug(f\"Failed to set up Chrome WebDriver: {str(e)}\", \"ERROR\")\n",
    "        print_debug(traceback.format_exc(), \"ERROR\")\n",
    "        raise\n",
    "\n",
    "def download_image(url, filename, download_dir):\n",
    "    \"\"\"Download an image from URL and save it with the given filename.\"\"\"\n",
    "    try:\n",
    "        print_debug(f\"Downloading image from {url[:50]}...\")\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        filepath = os.path.join(download_dir, filename)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print_debug(f\"Downloaded: {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print_debug(f\"Error downloading {url}: {str(e)}\", \"ERROR\")\n",
    "        return False\n",
    "\n",
    "def check_page_loaded(driver):\n",
    "    \"\"\"Check if the page has loaded properly and get diagnostic information.\"\"\"\n",
    "    print_debug(\"Checking page load status\")\n",
    "    \n",
    "    # Get current URL\n",
    "    current_url = driver.current_url\n",
    "    print_debug(f\"Current URL: {current_url}\")\n",
    "    \n",
    "    # Check page title\n",
    "    title = driver.title\n",
    "    print_debug(f\"Page title: {title}\")\n",
    "    \n",
    "    # Take screenshot for debugging\n",
    "    screenshot_path = os.path.join(os.getcwd(), \"asos_debug_screenshot.png\")\n",
    "    try:\n",
    "        driver.save_screenshot(screenshot_path)\n",
    "        print_debug(f\"Screenshot saved to {screenshot_path}\")\n",
    "    except Exception as e:\n",
    "        print_debug(f\"Failed to save screenshot: {str(e)}\", \"ERROR\")\n",
    "    \n",
    "    # Check page source length\n",
    "    source_length = len(driver.page_source)\n",
    "    print_debug(f\"Page source length: {source_length} characters\")\n",
    "    \n",
    "    # Check if we're being blocked or redirected\n",
    "    if \"robot\" in driver.page_source.lower() or \"captcha\" in driver.page_source.lower():\n",
    "        print_debug(\"Possible bot detection on the page!\", \"WARNING\")\n",
    "    \n",
    "    # Try to find common elements to verify page loaded correctly\n",
    "    try:\n",
    "        body_text = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "        print_debug(f\"Body text preview: {body_text[:100]}...\")\n",
    "    except:\n",
    "        print_debug(\"Could not extract body text\", \"WARNING\")\n",
    "    \n",
    "    return source_length > 1000  # Basic check if we have substantial content\n",
    "\n",
    "def download_asos_images(category, max_images=100, base_url=\"https://www.asos.com/us/\"):\n",
    "    \"\"\"\n",
    "    Download images from ASOS for a specific category with a maximum limit.\n",
    "    \n",
    "    Args:\n",
    "        category: String representing the clothing category (e.g., 'tops', 'dresses')\n",
    "        max_images: Maximum number of images to download\n",
    "        base_url: Base URL for ASOS\n",
    "    \"\"\"\n",
    "    # Create directory for downloaded images\n",
    "    download_dir = os.path.join(os.getcwd(), f'asos-{category}')\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    \n",
    "    # Build the category URL\n",
    "    if category == 'tops':\n",
    "        category_url = f\"{base_url}women/tops/cat/?cid=4169\"\n",
    "    elif category == 'dresses':\n",
    "        category_url = f\"{base_url}women/dresses/cat/?cid=8799\"\n",
    "    elif category == 'shoes':\n",
    "        category_url = f\"{base_url}women/shoes/cat/?cid=4172\"\n",
    "    elif category == 'jackets':\n",
    "        category_url = f\"{base_url}women/jackets-coats/cat/?cid=2641\"\n",
    "    elif category == 'jeans':\n",
    "        category_url = f\"{base_url}women/jeans/cat/?cid=3630\"\n",
    "    elif category == 'skirts':\n",
    "        category_url = f\"{base_url}women/skirts/cat/?cid=2639\"\n",
    "    elif category == 'bags':\n",
    "        category_url = f\"{base_url}women/bags-purses/cat/?cid=8730\"\n",
    "    elif category == 'suits':\n",
    "        category_url = f\"{base_url}women/suits-separates/cat/?cid=13632\"\n",
    "    else:\n",
    "        # Default to category-based URL pattern\n",
    "        category_url = f\"{base_url}women/{category}/cat/\"\n",
    "    \n",
    "    driver = None\n",
    "    try:\n",
    "        driver = setup_driver()\n",
    "        \n",
    "        # Navigate to the target URL\n",
    "        print_debug(f\"Navigating to {category_url}\")\n",
    "        driver.get(category_url)\n",
    "        \n",
    "        # Check if page loaded properly\n",
    "        if not check_page_loaded(driver):\n",
    "            print_debug(\"Page did not load properly\", \"ERROR\")\n",
    "            return\n",
    "        \n",
    "        # Wait a bit to let JavaScript initialize\n",
    "        print_debug(\"Waiting for initial page load\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # List of possible selectors for product elements\n",
    "        product_selectors = [\n",
    "            \"[data-auto-id='productTile']\",\n",
    "            \"article\",\n",
    "            \".productTile\",\n",
    "            \".product-card\",\n",
    "            \".product\",\n",
    "            \".styles__ProductCard\",\n",
    "            \"[data-testid='product']\"\n",
    "        ]\n",
    "        \n",
    "        # Check for product tiles with more detailed error handling\n",
    "        print_debug(\"Looking for product tiles\")\n",
    "        \n",
    "        product_selector = None\n",
    "        for selector in product_selectors:\n",
    "            try:\n",
    "                WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "                )\n",
    "                print_debug(f\"Product tiles found with selector: {selector}\")\n",
    "                product_selector = selector\n",
    "                break\n",
    "            except TimeoutException:\n",
    "                print_debug(f\"Selector {selector} not found\", \"INFO\")\n",
    "        \n",
    "        if not product_selector:\n",
    "            print_debug(\"Could not find any products on the page\", \"ERROR\")\n",
    "            return\n",
    "        \n",
    "        # Accept cookies if the banner appears\n",
    "        try:\n",
    "            print_debug(\"Checking for cookie consent banner\")\n",
    "            cookie_selectors = [\n",
    "                \"#onetrust-accept-btn-handler\",\n",
    "                \".cookie-accept\",\n",
    "                \"[data-testid='cookie-accept']\",\n",
    "                \"[aria-label='Accept cookies']\",\n",
    "                \".cookie-banner button\"\n",
    "            ]\n",
    "            \n",
    "            for selector in cookie_selectors:\n",
    "                try:\n",
    "                    cookie_button = WebDriverWait(driver, 3).until(\n",
    "                        EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n",
    "                    )\n",
    "                    cookie_button.click()\n",
    "                    print_debug(f\"Accepted cookies using selector: {selector}\")\n",
    "                    time.sleep(2)  # Wait for banner to disappear\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print_debug(f\"Cookie handling error or no cookie banner: {str(e)}\", \"INFO\")\n",
    "        \n",
    "        downloaded_urls = set()  # To avoid duplicates\n",
    "        product_count = 0\n",
    "        page_count = 1\n",
    "        \n",
    "        while product_count < max_images:\n",
    "            print_debug(f\"Processing page {page_count}\")\n",
    "            # Wait for products to load\n",
    "            time.sleep(3)  # Give more time for images to load\n",
    "            \n",
    "            # Find all product tiles\n",
    "            try:\n",
    "                product_tiles = driver.find_elements(By.CSS_SELECTOR, product_selector)\n",
    "                print_debug(f\"Found {len(product_tiles)} products on page {page_count}\")\n",
    "                \n",
    "                if not product_tiles:\n",
    "                    print_debug(\"No product tiles found on this page\", \"WARNING\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print_debug(f\"Error finding product tiles: {str(e)}\", \"ERROR\")\n",
    "                break\n",
    "            \n",
    "            # Extract and download images\n",
    "            for i, tile in enumerate(product_tiles):\n",
    "                if product_count >= max_images:\n",
    "                    print_debug(f\"Reached maximum image count ({max_images}). Stopping.\")\n",
    "                    return\n",
    "                \n",
    "                try:\n",
    "                    # Try different ways to find the image\n",
    "                    img_element = None\n",
    "                    img_url = None\n",
    "                    \n",
    "                    # Methods to find images\n",
    "                    try:\n",
    "                        img_element = tile.find_element(By.CSS_SELECTOR, \"img\")\n",
    "                        img_url = img_element.get_attribute(\"src\")\n",
    "                    except:\n",
    "                        try:\n",
    "                            # Sometimes images are in background CSS\n",
    "                            background_img = tile.value_of_css_property('background-image')\n",
    "                            if background_img and background_img != 'none':\n",
    "                                img_url = background_img.replace('url(\"', '').replace('\")', '')\n",
    "                        except:\n",
    "                            # Try looking for data-src attribute which is common for lazy-loaded images\n",
    "                            try:\n",
    "                                img_element = tile.find_element(By.CSS_SELECTOR, \"[data-src]\")\n",
    "                                img_url = img_element.get_attribute(\"data-src\")\n",
    "                            except:\n",
    "                                pass\n",
    "                    \n",
    "                    # Skip if no image URL or already downloaded\n",
    "                    if not img_url or img_url in downloaded_urls or img_url.startswith('data:'):\n",
    "                        continue\n",
    "                    \n",
    "                    # Clean up URL (some src attributes might have query parameters)\n",
    "                    img_url = img_url.split('?')[0]\n",
    "                    \n",
    "                    # Generate a filename from the URL\n",
    "                    filename = f\"{category}_{product_count}_{os.path.basename(urllib.parse.urlparse(img_url).path)}\"\n",
    "                    if not filename.endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp')):\n",
    "                        filename += \".jpg\"  # Add default extension if none is present\n",
    "                    \n",
    "                    # Download the image\n",
    "                    if download_image(img_url, filename, download_dir):\n",
    "                        downloaded_urls.add(img_url)\n",
    "                        product_count += 1\n",
    "                        print_debug(f\"Downloaded {product_count}/{max_images} images\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print_debug(f\"Error processing product: {str(e)}\", \"ERROR\")\n",
    "            \n",
    "            # If we haven't reached the maximum, try to load more products\n",
    "            if product_count < max_images:\n",
    "                # Try to find and click the \"Load more\" button\n",
    "                try:\n",
    "                    print_debug(\"Looking for 'Load more' button\")\n",
    "                    # Try multiple selectors for the load more button\n",
    "                    load_more_selectors = [\n",
    "                        \"[data-auto-id='loadMoreProducts']\",\n",
    "                        \".load-more\", \n",
    "                        \".loadMore\", \n",
    "                        \"[data-test='load-more']\"\n",
    "                    ]\n",
    "                    \n",
    "                    load_more_found = False\n",
    "                    for selector in load_more_selectors:\n",
    "                        try:\n",
    "                            load_more_button = WebDriverWait(driver, 5).until(\n",
    "                                EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n",
    "                            )\n",
    "                            \n",
    "                            # Scroll to the button to make it visible\n",
    "                            driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", load_more_button)\n",
    "                            time.sleep(2)  # Small pause after scrolling\n",
    "                            \n",
    "                            try:\n",
    "                                load_more_button.click()\n",
    "                                print_debug(\"Clicked 'Load more' button\")\n",
    "                                load_more_found = True\n",
    "                                break\n",
    "                            except ElementClickInterceptedException:\n",
    "                                # If the button is intercepted, try using JavaScript to click it\n",
    "                                driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "                                print_debug(\"Used JavaScript to click 'Load more' button\")\n",
    "                                load_more_found = True\n",
    "                                break\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    if not load_more_found:\n",
    "                        print_debug(\"No 'Load more' button found - we may have reached the end\", \"INFO\")\n",
    "                        break\n",
    "                    \n",
    "                    page_count += 1\n",
    "                    # Wait for new products to load\n",
    "                    time.sleep(5)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print_debug(f\"Error with 'Load more' button: {str(e)}\", \"INFO\")\n",
    "                    print_debug(\"Completed downloading or encountered an error with pagination.\")\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print_debug(f\"Total products downloaded: {product_count}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print_debug(f\"A critical error occurred: {str(e)}\", \"ERROR\")\n",
    "        print_debug(traceback.format_exc(), \"ERROR\")\n",
    "    \n",
    "    finally:\n",
    "        if driver:\n",
    "            print_debug(\"Closing Chrome WebDriver\")\n",
    "            driver.quit()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to download images from ASOS categories.\n",
    "    Change the parameters below to customize the download:\n",
    "    - categories: List of clothing categories to download\n",
    "    - max_images_per_category: Maximum number of images to download per category\n",
    "    \"\"\"\n",
    "    # Configuration - MODIFY THESE VALUES\n",
    "    categories = ['tops', 'dresses', 'jackets', 'shoes']\n",
    "    max_images_per_category = 50  # Set the maximum number of images per category\n",
    "    \n",
    "    # Process each category\n",
    "    for category in categories:\n",
    "        print_debug(f\"Starting download for category: {category}\")\n",
    "        download_asos_images(category=category, max_images=max_images_per_category)\n",
    "        print_debug(f\"Completed download for category: {category}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clarifai-grpc in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (11.2.6)\n",
      "Requirement already satisfied: grpcio>=1.53.2 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from clarifai-grpc) (1.70.0)\n",
      "Requirement already satisfied: protobuf>=3.20.3 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from clarifai-grpc) (5.29.3)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.57.0 in /Users/lilysu/anaconda3/envs/py311/lib/python3.11/site-packages (from clarifai-grpc) (1.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install clarifai-grpc\n",
    "\n",
    "from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "from clarifai_grpc.grpc.api import service_pb2_grpc, service_pb2, resources_pb2\n",
    "from clarifai_grpc.grpc.api.status import status_code_pb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PAT: 54e90...d229 (masked for security)\n",
      "Using model: user_id=clarifai, app_id=main, model_id=apparel-classification-v2, version=651c5412d53c408fa3b4fe3dcc060be7\n",
      "Processing asos-tops directory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-tops/tops_43_.jpg - long-sleeve (0.97); top (0.89); shirt (0.83); v-neck (0.71); 3/4 sleeve (0.62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-tops/tops_14_.jpg - crewneck (0.96); long-sleeve (0.91); graphic (0.90); coat (0.66); hoodie (0.63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing asos-shoes directory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-shoes/shoes_27_.jpg - leather (0.98); colorblock (0.97); boots (0.92); pants (0.55); chambray/denim (0.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-shoes/shoes_31_.jpg - sleeveless (0.94); leather (0.90); colorblock (0.66); pants (0.62); midi dress (0.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing asos-products directory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-products/asos_3_.jpg - floral (0.98); midi dress (0.94); sleeveless (0.94); maxi dress (0.92); v-neck (0.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-products/asos_106_.jpg - graphic (1.00); long-sleeve (0.98); crewneck (0.95); sweatshirt (0.84); hoodie (0.68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing asos-jackets directory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-jackets/jackets_6_.jpg - long-sleeve (0.97); hoodie (0.81); coat (0.69); leather (0.63); colorblock (0.54)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-jackets/jackets_30_.jpg - long-sleeve (0.98); fur (0.92); coat (0.88); hoodie (0.81); jacket (0.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing asos-dresses directory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-dresses/dresses_6_.jpg - maxi dress (0.95); midi dress (0.91); chiffon (0.86); crewneck (0.86); v-neck (0.83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: asos-dresses/dresses_7_.jpg - shoulder bag (0.93); leather (0.88); floral (0.80); maxi dress (0.79); scarf (0.73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to clarifai_classification_asos.json\n",
      "Processed results saved to processed_classifications.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import dotenv\n",
    "import traceback\n",
    "import base64\n",
    "\n",
    "def classify_apparel_images(\n",
    "    directories: List[str],\n",
    "    max_images_per_dir: Dict[str, int],\n",
    "    pat: str,\n",
    "    user_id: str = \"clarifai\",\n",
    "    app_id: str = \"main\",\n",
    "    model_id: str = \"apparel-classification-v2\",\n",
    "    model_version_id: str = \"651c5412d53c408fa3b4fe3dcc060be7\",\n",
    "    max_concepts: int = 5,  # New parameter to specify maximum number of concepts to return\n",
    "    output_file: Optional[str] = \"classification_results.json\",\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Classify apparel images in specified directories using Clarifai API.\n",
    "\n",
    "    Args:\n",
    "        directories: List of directory names containing apparel images\n",
    "        max_images_per_dir: Dictionary mapping directory names to maximum number of images to process\n",
    "        pat: Clarifai Personal Access Token\n",
    "        user_id: Clarifai user ID\n",
    "        app_id: Clarifai app ID\n",
    "        model_id: Clarifai model ID\n",
    "        model_version_id: Optional model version ID (defaults to latest if None)\n",
    "        max_concepts: Maximum number of concepts to return per image\n",
    "        output_file: Optional file path to save results (None to skip saving)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing classification results for each image\n",
    "    \"\"\"\n",
    "    print(f\"Using model: user_id={user_id}, app_id={app_id}, model_id={model_id}, version={model_version_id}\")\n",
    "    \n",
    "    # Set up the gRPC client\n",
    "    channel = ClarifaiChannel.get_grpc_channel()\n",
    "    stub = service_pb2_grpc.V2Stub(channel)\n",
    "    metadata = (('authorization', 'Key ' + pat),)\n",
    "    user_data_object = resources_pb2.UserAppIDSet(user_id=user_id, app_id=app_id)\n",
    "\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    # Process each directory\n",
    "    for directory in directories:\n",
    "        print(f\"Processing {directory} directory...\")\n",
    "\n",
    "        # Get image paths in the directory\n",
    "        image_pattern = os.path.join(directory, \"*.jpg\")\n",
    "        image_paths = glob.glob(image_pattern)\n",
    "\n",
    "        # Determine how many images to process\n",
    "        max_images = max_images_per_dir.get(directory, 10)  # Default to 10 if not specified\n",
    "        image_paths = image_paths[:max_images]\n",
    "\n",
    "        # Process each image\n",
    "        for image_path in tqdm(image_paths):\n",
    "            try:\n",
    "                # Read image file as bytes\n",
    "                with open(image_path, \"rb\") as f:\n",
    "                    image_bytes = f.read()\n",
    "                \n",
    "                # Create the request with file bytes instead of URL\n",
    "                post_model_outputs_response = stub.PostModelOutputs(\n",
    "                    service_pb2.PostModelOutputsRequest(\n",
    "                        user_app_id=user_data_object,\n",
    "                        model_id=model_id,\n",
    "                        version_id=model_version_id,\n",
    "                        inputs=[\n",
    "                            resources_pb2.Input(\n",
    "                                data=resources_pb2.Data(\n",
    "                                    image=resources_pb2.Image(\n",
    "                                        base64=image_bytes\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "                        ]\n",
    "                    ),\n",
    "                    metadata=metadata\n",
    "                )\n",
    "\n",
    "                # Check for errors in the API response\n",
    "                if post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n",
    "                    error_msg = f\"API Error: {post_model_outputs_response.status.description}\"\n",
    "                    print(error_msg)\n",
    "                    results[image_path] = f\"Error: {error_msg}\"\n",
    "                    continue\n",
    "\n",
    "                # Get the output from the response\n",
    "                output = post_model_outputs_response.outputs[0]\n",
    "                \n",
    "                # Extract top concepts\n",
    "                if len(output.data.concepts) > 0:\n",
    "                    # Sort concepts by value (confidence score) in descending order\n",
    "                    concepts = sorted(output.data.concepts, key=lambda c: c.value, reverse=True)\n",
    "                    \n",
    "                    # Get up to max_concepts or all available if fewer\n",
    "                    top_concepts = concepts[:max_concepts]\n",
    "                    \n",
    "                    # Format the classifications\n",
    "                    classifications = [f\"{c.name} ({c.value:.2f})\" for c in top_concepts]\n",
    "                    \n",
    "                    # Join with semicolons for better readability\n",
    "                    classification_str = \"; \".join(classifications)\n",
    "                else:\n",
    "                    classification_str = \"No concepts found\"\n",
    "\n",
    "                # Store result\n",
    "                results[image_path] = classification_str\n",
    "                print(f\"Success: {image_path} - {classification_str}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                # Get detailed error information\n",
    "                error_details = traceback.format_exc()\n",
    "                print(f\"Error processing {image_path}:\")\n",
    "                print(error_details)\n",
    "                results[image_path] = f\"Error: {str(e)}\"\n",
    "\n",
    "            # Add a delay to avoid rate limiting\n",
    "            time.sleep(2.0)\n",
    "\n",
    "    # Save results to file if specified\n",
    "    if output_file:\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def process_classification_results(results_file: str) -> dict:\n",
    "    \"\"\"\n",
    "    Process classification results to extract only the item names without confidence scores.\n",
    "    \n",
    "    Args:\n",
    "        results_file: Path to the JSON file containing classification results\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with image paths as keys and lists of item names as values\n",
    "    \"\"\"\n",
    "    # Load the results from the JSON file\n",
    "    with open(results_file, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    # Dictionary to store processed results\n",
    "    processed_results = {}\n",
    "    \n",
    "    # Process each image result\n",
    "    for image_path, classifications in results.items():\n",
    "        # Skip error entries\n",
    "        if classifications.startswith(\"Error\") or classifications == \"No concepts found\":\n",
    "            processed_results[image_path] = []\n",
    "            continue\n",
    "        \n",
    "        # Split classifications by semicolon\n",
    "        items_with_scores = classifications.split('; ')\n",
    "        \n",
    "        # Extract just the item names (remove the confidence scores)\n",
    "        items = []\n",
    "        for item_with_score in items_with_scores:\n",
    "            # Extract the item name (everything before the opening parenthesis)\n",
    "            item_name = item_with_score.split(' (')[0]\n",
    "            items.append(item_name)\n",
    "        \n",
    "        # Store in the processed results dictionary\n",
    "        processed_results[image_path] = items\n",
    "    \n",
    "    # Save the processed results to a new JSON file\n",
    "    output_file = 'clarifai_classification_asos.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(processed_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Processed results saved to {output_file}\")\n",
    "    \n",
    "    return processed_results\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load environment variables from .env file\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Get PAT from environment variable\n",
    "    pat = os.environ.get(\"PAT\")\n",
    "\n",
    "    if not pat:\n",
    "        print(\n",
    "            \"Error: PAT environment variable not found. Please set PAT in your .env file.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    print(\n",
    "        f\"Using PAT: {pat[:5]}...{pat[-4:] if len(pat) > 8 else ''} (masked for security)\"\n",
    "    )\n",
    "\n",
    "    # List of apparel directories\n",
    "    directories = [\n",
    "        \"asos-tops\",\n",
    "        \"asos-shoes\",\n",
    "        \"asos-products\",\n",
    "        \"asos-jackets\",\n",
    "        \"asos-dresses\",\n",
    "    ]\n",
    "\n",
    "    # Set maximum images to process for each directory\n",
    "    max_images_per_dir = {\n",
    "        \"asos-tops\": 2,\n",
    "        \"asos-shoes\": 2,\n",
    "        \"asos-products\": 2,\n",
    "        \"asos-jackets\": 2,\n",
    "        \"asos-dresses\": 2,\n",
    "    }\n",
    "\n",
    "    output_file = \"clarifai_classification_asos.json\"\n",
    "    \n",
    "    # Classify images\n",
    "    results = classify_apparel_images(\n",
    "        directories=directories,\n",
    "        max_images_per_dir=max_images_per_dir,\n",
    "        pat=pat,\n",
    "        max_concepts=5,  # Get up to 5 classifications per image\n",
    "        output_file=output_file,\n",
    "    )\n",
    "\n",
    "    # Process the results to extract just the item names\n",
    "    processed_results = process_classification_results(output_file)\n",
    "    \n",
    "    return processed_results\n",
    "\n",
    "\n",
    "# processed_results = process_classification_results(\"clarifai_classification_asos.json\")\n",
    "# processed_results\n",
    "\n",
    "results = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing asos-tops/tops_43_.jpg - long-sleeve\n",
      "Processing asos-tops/tops_43_.jpg - top\n",
      "Processing asos-tops/tops_43_.jpg - shirt\n",
      "Processing asos-tops/tops_43_.jpg - v-neck\n",
      "Processing asos-tops/tops_43_.jpg - 3/4 sleeve\n",
      "Processing asos-tops/tops_14_.jpg - crewneck\n",
      "Processing asos-tops/tops_14_.jpg - long-sleeve\n",
      "Processing asos-tops/tops_14_.jpg - graphic\n",
      "Processing asos-tops/tops_14_.jpg - coat\n",
      "Processing asos-tops/tops_14_.jpg - hoodie\n",
      "Processing asos-shoes/shoes_27_.jpg - leather\n",
      "Processing asos-shoes/shoes_27_.jpg - colorblock\n",
      "Processing asos-shoes/shoes_27_.jpg - boots\n",
      "Processing asos-shoes/shoes_27_.jpg - pants\n",
      "Processing asos-shoes/shoes_27_.jpg - chambray/denim\n",
      "Processing asos-shoes/shoes_31_.jpg - sleeveless\n",
      "Processing asos-shoes/shoes_31_.jpg - leather\n",
      "Processing asos-shoes/shoes_31_.jpg - colorblock\n",
      "Processing asos-shoes/shoes_31_.jpg - pants\n",
      "Processing asos-shoes/shoes_31_.jpg - midi dress\n",
      "Processing asos-products/asos_3_.jpg - floral\n",
      "Processing asos-products/asos_3_.jpg - midi dress\n",
      "Processing asos-products/asos_3_.jpg - sleeveless\n",
      "Processing asos-products/asos_3_.jpg - maxi dress\n",
      "Processing asos-products/asos_3_.jpg - v-neck\n",
      "Processing asos-products/asos_106_.jpg - graphic\n",
      "Processing asos-products/asos_106_.jpg - long-sleeve\n",
      "Processing asos-products/asos_106_.jpg - crewneck\n",
      "Processing asos-products/asos_106_.jpg - sweatshirt\n",
      "Processing asos-products/asos_106_.jpg - hoodie\n",
      "Processing asos-jackets/jackets_6_.jpg - long-sleeve\n",
      "Processing asos-jackets/jackets_6_.jpg - hoodie\n",
      "Processing asos-jackets/jackets_6_.jpg - coat\n",
      "Processing asos-jackets/jackets_6_.jpg - leather\n",
      "Processing asos-jackets/jackets_6_.jpg - colorblock\n",
      "Processing asos-jackets/jackets_30_.jpg - long-sleeve\n",
      "Processing asos-jackets/jackets_30_.jpg - fur\n",
      "Processing asos-jackets/jackets_30_.jpg - coat\n",
      "Processing asos-jackets/jackets_30_.jpg - hoodie\n",
      "Processing asos-jackets/jackets_30_.jpg - jacket\n",
      "Processing asos-dresses/dresses_6_.jpg - maxi dress\n",
      "Processing asos-dresses/dresses_6_.jpg - midi dress\n",
      "Processing asos-dresses/dresses_6_.jpg - chiffon\n",
      "Processing asos-dresses/dresses_6_.jpg - crewneck\n",
      "Processing asos-dresses/dresses_6_.jpg - v-neck\n",
      "Processing asos-dresses/dresses_7_.jpg - shoulder bag\n",
      "Processing asos-dresses/dresses_7_.jpg - leather\n",
      "Processing asos-dresses/dresses_7_.jpg - floral\n",
      "Processing asos-dresses/dresses_7_.jpg - maxi dress\n",
      "Processing asos-dresses/dresses_7_.jpg - scarf\n",
      "Analysis complete. Results saved to anthropic_asos_descriptions.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('fashion_data_output')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import glob\n",
    "from anthropic import Anthropic\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def initialize_anthropic_client():\n",
    "    api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"Error: ANTHROPIC_API_KEY not found in environment variables.\")\n",
    "        return None\n",
    "    return Anthropic(api_key=api_key)\n",
    "\n",
    "def analyze_attribute_with_claude(client, image_path, attribute):\n",
    "    \"\"\"Analyze a single attribute of a garment using Claude.\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at path: {image_path}\")\n",
    "        return {\"error\": \"Image file not found.\"}\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"image/jpeg\",\n",
    "                        \"data\": encoded_string\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"\"\"For this garment, focus only on the '{attribute}' aspect. \n",
    "                    Return a JSON object with: color, material, occasion, style, season, unique_feature, era, \n",
    "                    casual_or_relaxed (boolean), visual_aesthetic, hardware.\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-latest\",\n",
    "            max_tokens=800,\n",
    "            system=\"You are a fashion analyst focused on specific garment attributes.\",\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        response_text = response.content[0].text\n",
    "        json_start = response_text.find('{')\n",
    "        json_end = response_text.rfind('}') + 1\n",
    "        \n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_content = response_text[json_start:json_end]\n",
    "            try:\n",
    "                return json.loads(json_content)\n",
    "            except json.JSONDecodeError:\n",
    "                return {\"error\": \"Failed to parse JSON response\"}\n",
    "        else:\n",
    "            return {\"error\": \"No JSON in response\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error processing image: {e}\"}\n",
    "\n",
    "def describe_clothing_item_attributes(json_path, base_img_dir=\"\"):\n",
    "    client = initialize_anthropic_client()\n",
    "    if not client:\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        with open(json_path, 'r') as file:\n",
    "            processed_results = json.load(file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error loading JSON: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    detailed_descriptions = {}\n",
    "    \n",
    "    for image_path, attributes in processed_results.items():\n",
    "        # Only process images from folders that start with \"asos-\"\n",
    "        if not image_path.startswith(\"asos-\"):\n",
    "            continue\n",
    "            \n",
    "        full_image_path = os.path.join(base_img_dir, image_path) if base_img_dir else image_path\n",
    "        \n",
    "        # Create a list to store descriptions for each attribute\n",
    "        attribute_descriptions = []\n",
    "        \n",
    "        for attribute in attributes:\n",
    "            print(f\"Processing {image_path} - {attribute}\")\n",
    "            \n",
    "            # Get detailed analysis from Claude for this specific attribute\n",
    "            attribute_details = analyze_attribute_with_claude(client, full_image_path, attribute)\n",
    "            \n",
    "            # Add the attribute name to the details\n",
    "            attribute_details[\"attribute\"] = attribute\n",
    "            attribute_descriptions.append(attribute_details)\n",
    "        \n",
    "        # Store the list of attribute descriptions for this image\n",
    "        detailed_descriptions[image_path] = attribute_descriptions\n",
    "    \n",
    "    return detailed_descriptions\n",
    "\n",
    "def parse_fashion_data(input_text):\n",
    "    \"\"\"\n",
    "    Parse the fashion description data and convert it to structured formats\n",
    "    \"\"\"\n",
    "    # Convert input to dictionary if it's a string\n",
    "    if isinstance(input_text, str):\n",
    "        data_dict = json.loads(input_text.replace(\"'\", '\"'))\n",
    "    else:\n",
    "        data_dict = input_text  # Assume it's already a dictionary\n",
    "        \n",
    "    structured_data = []\n",
    "    for image_path, descriptions in data_dict.items():\n",
    "        # Check if this is a folder starting with \"asos-\"\n",
    "        if image_path.split('/')[0].startswith(\"asos-\"):\n",
    "            category = image_path.split('/')[0].split('-')[-1]\n",
    "            entry = {\n",
    "                'image_path': image_path,\n",
    "                'category': category,\n",
    "                'item_id': image_path.split('_')[1] if len(image_path.split('_')) > 1 else \"\",\n",
    "                'description': descriptions\n",
    "            }\n",
    "            structured_data.append(entry)\n",
    "    \n",
    "    return pd.DataFrame(structured_data)\n",
    "\n",
    "def format_as_json(df):\n",
    "    \"\"\"\n",
    "    Format the dataframe as JSON\n",
    "    \"\"\"\n",
    "    return df.to_json(orient='records', indent=2)\n",
    "\n",
    "def save_outputs(data_text, output_dir='fashion_data_output'):\n",
    "    \"\"\"\n",
    "    Save the data in various formats\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "        \n",
    "    return output_path\n",
    "\n",
    "def process_asos_folders(base_img_dir=\"\"):\n",
    "    \"\"\"\n",
    "    Find all asos-* folders and process their contents\n",
    "    \"\"\"\n",
    "    # Find all asos-* folders\n",
    "    asos_folders = glob.glob(\"asos-*\")\n",
    "    \n",
    "    # Load classification data\n",
    "    try:\n",
    "        with open(\"clarifai_classification_asos.json\", 'r') as file:\n",
    "            processed_results = json.load(file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error loading JSON: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    # Initialize Anthropic client\n",
    "    client = initialize_anthropic_client()\n",
    "    if not client:\n",
    "        return {}\n",
    "    \n",
    "    # Structure to hold all results\n",
    "    detailed_descriptions = {}\n",
    "    \n",
    "    # Process each image in the classification results\n",
    "    for image_path, attributes in processed_results.items():\n",
    "        # Check if this image is from an asos- folder\n",
    "        folder_name = image_path.split('/')[0]\n",
    "        if not folder_name.startswith(\"asos-\"):\n",
    "            continue\n",
    "            \n",
    "        full_image_path = os.path.join(base_img_dir, image_path) if base_img_dir else image_path\n",
    "        \n",
    "        # Create a list to store descriptions for each attribute\n",
    "        attribute_descriptions = []\n",
    "        \n",
    "        for attribute in attributes:\n",
    "            print(f\"Processing {image_path} - {attribute}\")\n",
    "            \n",
    "            # Get detailed analysis from Claude for this specific attribute\n",
    "            attribute_details = analyze_attribute_with_claude(client, full_image_path, attribute)\n",
    "            \n",
    "            # Add the attribute name to the details\n",
    "            attribute_details[\"attribute\"] = attribute\n",
    "            attribute_descriptions.append(attribute_details)\n",
    "        \n",
    "        # Store the list of attribute descriptions for this image\n",
    "        detailed_descriptions[image_path] = attribute_descriptions\n",
    "    \n",
    "    # Save results to a file\n",
    "    with open(\"anthropic_asos_descriptions.json\", \"w\") as f:\n",
    "        json.dump(detailed_descriptions, f, indent=2)\n",
    "    \n",
    "    print(f\"Analysis complete. Results saved to anthropic_asos_descriptions.json\")\n",
    "    \n",
    "    return detailed_descriptions\n",
    "\n",
    "results = process_asos_folders()\n",
    "\n",
    "# # Save formatted outputs\n",
    "output_paths = save_outputs(results)\n",
    "output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PAT: 54e90...d229 (masked for security)\n",
      "Using model: user_id=clarifai, app_id=main, model_id=apparel-classification-v2, version=651c5412d53c408fa3b4fe3dcc060be7\n",
      "Processing images from user folder...\n",
      "Found 8 images in user (processing up to 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: user/IMG_7394.JPG - pants (0.90); knit (0.75); long-sleeve (0.74); top (0.54); crewneck (0.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:09<01:05,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: user/IMG_7344.JPG - pants (0.90); long-sleeve (0.85); knit (0.68); crewneck (0.64); coat (0.58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:13<00:37,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: user/IMG_7268.JPG - pants (0.94); knit (0.67); suit pants (0.66); long-sleeve (0.57); sweatpants (0.54)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:18<00:27,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: user/IMG_7446.JPG - long-sleeve (0.88); crewneck (0.74); knit (0.73); pants (0.71); graphic (0.64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:23<00:22,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: user/IMG_7453.JPG - long-sleeve (0.93); coat (0.74); pants (0.68); crewneck (0.56); knit (0.50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:29<00:17,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: user/IMG_7336.JPG - pants (0.90); long-sleeve (0.72); knit (0.69); crewneck (0.67); t-shirt (0.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:35<00:11,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: user/IMG_7503.JPG - pants (0.88); crewneck (0.71); long-sleeve (0.68); graphic (0.65); t-shirt (0.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:39<00:05,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: user/IMG_7567.JPG - pants (0.86); long-sleeve (0.75); crewneck (0.61); graphic (0.58); knit (0.58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:44<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to user_classification_results.json\n",
      "Processed results saved to user_processed_classifications.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import dotenv\n",
    "import traceback\n",
    "import base64\n",
    "\n",
    "def clarifai_classification(\n",
    "    pat: str,\n",
    "    user_id: str = \"clarifai\",\n",
    "    app_id: str = \"main\",\n",
    "    model_id: str = \"apparel-classification-v2\",\n",
    "    model_version_id: str = \"651c5412d53c408fa3b4fe3dcc060be7\",\n",
    "    max_concepts: int = 5,\n",
    "    max_images: int = 10,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Classify apparel images in the user folder using Clarifai API.\n",
    "\n",
    "    Args:\n",
    "        pat: Clarifai Personal Access Token\n",
    "        user_id: Clarifai user ID\n",
    "        app_id: Clarifai app ID\n",
    "        model_id: Clarifai model ID\n",
    "        model_version_id: Optional model version ID (defaults to latest if None)\n",
    "        max_concepts: Maximum number of concepts to return per image\n",
    "        max_images: Maximum number of images to process (default: 10)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing classification results for each image\n",
    "    \"\"\"\n",
    "    print(f\"Using model: user_id={user_id}, app_id={app_id}, model_id={model_id}, version={model_version_id}\")\n",
    "    \n",
    "    # Set up the gRPC client\n",
    "    channel = ClarifaiChannel.get_grpc_channel()\n",
    "    stub = service_pb2_grpc.V2Stub(channel)\n",
    "    metadata = (('authorization', 'Key ' + pat),)\n",
    "    user_data_object = resources_pb2.UserAppIDSet(user_id=user_id, app_id=app_id)\n",
    "\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    # Use \"user\" folder instead of multiple directories\n",
    "    user_folder = \"user\"\n",
    "    print(f\"Processing images from {user_folder} folder...\")\n",
    "\n",
    "    # Get image paths in the directory (supporting multiple image formats)\n",
    "    image_patterns = [\n",
    "        os.path.join(user_folder, \"*.JPG\")\n",
    "    ]\n",
    "    \n",
    "    # Collect all image paths\n",
    "    image_paths = []\n",
    "    for pattern in image_patterns:\n",
    "        image_paths.extend(glob.glob(pattern))\n",
    "\n",
    "    # Limit to max_images\n",
    "    image_paths = image_paths[:max_images]\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images in {user_folder} (processing up to {max_images})\")\n",
    "\n",
    "    # Process each image\n",
    "    for image_path in tqdm(image_paths):\n",
    "        try:\n",
    "            # Read image file as bytes\n",
    "            with open(image_path, \"rb\") as f:\n",
    "                image_bytes = f.read()\n",
    "            \n",
    "            # Create the request with file bytes instead of URL\n",
    "            post_model_outputs_response = stub.PostModelOutputs(\n",
    "                service_pb2.PostModelOutputsRequest(\n",
    "                    user_app_id=user_data_object,\n",
    "                    model_id=model_id,\n",
    "                    version_id=model_version_id,\n",
    "                    inputs=[\n",
    "                        resources_pb2.Input(\n",
    "                            data=resources_pb2.Data(\n",
    "                                image=resources_pb2.Image(\n",
    "                                    base64=image_bytes\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                metadata=metadata\n",
    "            )\n",
    "\n",
    "            # Check for errors in the API response\n",
    "            if post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n",
    "                error_msg = f\"API Error: {post_model_outputs_response.status.description}\"\n",
    "                print(error_msg)\n",
    "                results[image_path] = f\"Error: {error_msg}\"\n",
    "                continue\n",
    "\n",
    "            # Get the output from the response\n",
    "            output = post_model_outputs_response.outputs[0]\n",
    "            \n",
    "            # Extract top concepts\n",
    "            if len(output.data.concepts) > 0:\n",
    "                # Sort concepts by value (confidence score) in descending order\n",
    "                concepts = sorted(output.data.concepts, key=lambda c: c.value, reverse=True)\n",
    "                \n",
    "                # Get up to max_concepts or all available if fewer\n",
    "                top_concepts = concepts[:max_concepts]\n",
    "                \n",
    "                # Format the classifications\n",
    "                classifications = [f\"{c.name} ({c.value:.2f})\" for c in top_concepts]\n",
    "                \n",
    "                # Join with semicolons for better readability\n",
    "                classification_str = \"; \".join(classifications)\n",
    "            else:\n",
    "                classification_str = \"No concepts found\"\n",
    "\n",
    "            # Store result\n",
    "            results[image_path] = classification_str\n",
    "            print(f\"Success: {image_path} - {classification_str}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Get detailed error information\n",
    "            error_details = traceback.format_exc()\n",
    "            print(f\"Error processing {image_path}:\")\n",
    "            print(error_details)\n",
    "            results[image_path] = f\"Error: {str(e)}\"\n",
    "\n",
    "        # Add a delay to avoid rate limiting\n",
    "        time.sleep(2.0)\n",
    "\n",
    "    # Save results with \"user_\" prefix\n",
    "    output_file = \"user_classification_results.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    # Process the results and save with \"user_\" prefix\n",
    "    processed_results = process_classification_results(results, \"user_processed_classifications.json\")\n",
    "    \n",
    "    return processed_results\n",
    "\n",
    "def process_classification_results(results: dict, output_file: str = \"user_processed_classifications.json\") -> dict:\n",
    "    \"\"\"\n",
    "    Process classification results to extract only the item names without confidence scores.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary containing classification results\n",
    "        output_file: Path to save the processed results\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with image paths as keys and lists of item names as values\n",
    "    \"\"\"\n",
    "    # Dictionary to store processed results\n",
    "    processed_results = {}\n",
    "    \n",
    "    # Process each image result\n",
    "    for image_path, classifications in results.items():\n",
    "        # Skip error entries\n",
    "        if classifications.startswith(\"Error\") or classifications == \"No concepts found\":\n",
    "            processed_results[image_path] = []\n",
    "            continue\n",
    "        \n",
    "        # Split classifications by semicolon\n",
    "        items_with_scores = classifications.split('; ')\n",
    "        \n",
    "        # Extract just the item names (remove the confidence scores)\n",
    "        items = []\n",
    "        for item_with_score in items_with_scores:\n",
    "            # Extract the item name (everything before the opening parenthesis)\n",
    "            item_name = item_with_score.split(' (')[0]\n",
    "            items.append(item_name)\n",
    "        \n",
    "        # Store in the processed results dictionary\n",
    "        processed_results[image_path] = items\n",
    "    \n",
    "    # Save the processed results to a new JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(processed_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Processed results saved to {output_file}\")\n",
    "    \n",
    "    return processed_results\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Get PAT from environment variable\n",
    "pat = os.environ.get(\"PAT\")\n",
    "\n",
    "if not pat:\n",
    "    print(\"Error: PAT environment variable not found. Please set PAT in your .env file.\")\n",
    "else:\n",
    "    print(f\"Using PAT: {pat[:5]}...{pat[-4:] if len(pat) > 8 else ''} (masked for security)\")\n",
    "    \n",
    "    # Run the classification on the user folder\n",
    "    results = clarifai_classification(pat=pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user/IMG_7394.JPG - pants\n",
      "Processing user/IMG_7394.JPG - knit\n",
      "Processing user/IMG_7394.JPG - long-sleeve\n",
      "Processing user/IMG_7394.JPG - top\n",
      "Processing user/IMG_7394.JPG - crewneck\n",
      "Processing user/IMG_7344.JPG - pants\n",
      "Processing user/IMG_7344.JPG - long-sleeve\n",
      "Processing user/IMG_7344.JPG - knit\n",
      "Processing user/IMG_7344.JPG - crewneck\n",
      "Processing user/IMG_7344.JPG - coat\n",
      "Processing user/IMG_7268.JPG - pants\n",
      "Processing user/IMG_7268.JPG - knit\n",
      "Processing user/IMG_7268.JPG - suit pants\n",
      "Processing user/IMG_7268.JPG - long-sleeve\n",
      "Processing user/IMG_7268.JPG - sweatpants\n",
      "Processing user/IMG_7446.JPG - long-sleeve\n",
      "Processing user/IMG_7446.JPG - crewneck\n",
      "Processing user/IMG_7446.JPG - knit\n",
      "Processing user/IMG_7446.JPG - pants\n",
      "Processing user/IMG_7446.JPG - graphic\n",
      "Processing user/IMG_7453.JPG - long-sleeve\n",
      "Processing user/IMG_7453.JPG - coat\n",
      "Processing user/IMG_7453.JPG - pants\n",
      "Processing user/IMG_7453.JPG - crewneck\n",
      "Processing user/IMG_7453.JPG - knit\n",
      "Processing user/IMG_7336.JPG - pants\n",
      "Processing user/IMG_7336.JPG - long-sleeve\n",
      "Processing user/IMG_7336.JPG - knit\n",
      "Processing user/IMG_7336.JPG - crewneck\n",
      "Processing user/IMG_7336.JPG - t-shirt\n",
      "Processing user/IMG_7503.JPG - pants\n",
      "Processing user/IMG_7503.JPG - crewneck\n",
      "Processing user/IMG_7503.JPG - long-sleeve\n",
      "Processing user/IMG_7503.JPG - graphic\n",
      "Processing user/IMG_7503.JPG - t-shirt\n",
      "Processing user/IMG_7567.JPG - pants\n",
      "Processing user/IMG_7567.JPG - long-sleeve\n",
      "Processing user/IMG_7567.JPG - crewneck\n",
      "Processing user/IMG_7567.JPG - graphic\n",
      "Processing user/IMG_7567.JPG - knit\n",
      "Analysis complete. Results saved to anthropic_asos_descriptions.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'extract_key_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m results \u001b[38;5;241m=\u001b[39m process_asos_folders()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Save formatted outputs\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m output_paths \u001b[38;5;241m=\u001b[39m \u001b[43msave_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles saved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m format_name, path \u001b[38;5;129;01min\u001b[39;00m output_paths\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[8], line 151\u001b[0m, in \u001b[0;36msave_outputs\u001b[0;34m(data_text, output_dir)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Parse the data\u001b[39;00m\n\u001b[1;32m    150\u001b[0m df \u001b[38;5;241m=\u001b[39m parse_fashion_data(data_text)\n\u001b[0;32m--> 151\u001b[0m df_with_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_key_features\u001b[49m(df)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Save as JSON\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfashion_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_key_features' is not defined"
     ]
    }
   ],
   "source": [
    "def process_asos_folders(base_img_dir=\"\"):\n",
    "    \"\"\"\n",
    "    Find all asos-* folders and process their contents\n",
    "    \"\"\"\n",
    "    # Find all asos-* folders\n",
    "    asos_folders = glob.glob(\"user*\")\n",
    "    \n",
    "    # Load classification data\n",
    "    try:\n",
    "        with open(\"user_processed_classifications.json\", 'r') as file:\n",
    "            processed_results = json.load(file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error loading JSON: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    # Initialize Anthropic client\n",
    "    client = initialize_anthropic_client()\n",
    "    if not client:\n",
    "        return {}\n",
    "    \n",
    "    # Structure to hold all results\n",
    "    detailed_descriptions = {}\n",
    "    \n",
    "    # Process each image in the classification results\n",
    "    for image_path, attributes in processed_results.items():\n",
    "        # Check if this image is from an asos- folder\n",
    "        folder_name = image_path.split('/')[0]\n",
    "        if not folder_name.startswith(\"user\"):\n",
    "            continue\n",
    "            \n",
    "        full_image_path = os.path.join(base_img_dir, image_path) if base_img_dir else image_path\n",
    "        \n",
    "        # Create a list to store descriptions for each attribute\n",
    "        attribute_descriptions = []\n",
    "        \n",
    "        for attribute in attributes:\n",
    "            print(f\"Processing {image_path} - {attribute}\")\n",
    "            \n",
    "            # Get detailed analysis from Claude for this specific attribute\n",
    "            attribute_details = analyze_attribute_with_claude(client, full_image_path, attribute)\n",
    "            \n",
    "            # Add the attribute name to the details\n",
    "            attribute_details[\"attribute\"] = attribute\n",
    "            attribute_descriptions.append(attribute_details)\n",
    "        \n",
    "        # Store the list of attribute descriptions for this image\n",
    "        detailed_descriptions[image_path] = attribute_descriptions\n",
    "    \n",
    "    # Save results to a file\n",
    "    with open(\"anthropic_asos_descriptions.json\", \"w\") as f:\n",
    "        json.dump(detailed_descriptions, f, indent=2)\n",
    "    \n",
    "    print(f\"Analysis complete. Results saved to anthropic_asos_descriptions.json\")\n",
    "    \n",
    "    return detailed_descriptions\n",
    "\n",
    "results = process_asos_folders()\n",
    "\n",
    "# Save formatted outputs\n",
    "output_paths = save_outputs(results)\n",
    "print(\"Files saved to:\")\n",
    "for format_name, path in output_paths.items():\n",
    "    print(f\"- {format_name}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: asos-tops/tops_43_.jpg\n",
      "Successfully embedded asos-tops/tops_43_.jpg\n",
      "Processing: asos-tops/tops_14_.jpg\n",
      "Successfully embedded asos-tops/tops_14_.jpg\n",
      "Processing: asos-shoes/shoes_27_.jpg\n",
      "Successfully embedded asos-shoes/shoes_27_.jpg\n",
      "Processing: asos-shoes/shoes_31_.jpg\n",
      "Successfully embedded asos-shoes/shoes_31_.jpg\n",
      "Processing: asos-products/asos_3_.jpg\n",
      "Successfully embedded asos-products/asos_3_.jpg\n",
      "Processing: asos-products/asos_106_.jpg\n",
      "Successfully embedded asos-products/asos_106_.jpg\n",
      "Processing: asos-jackets/jackets_6_.jpg\n",
      "Successfully embedded asos-jackets/jackets_6_.jpg\n",
      "Processing: asos-jackets/jackets_30_.jpg\n",
      "Successfully embedded asos-jackets/jackets_30_.jpg\n",
      "Processing: asos-dresses/dresses_6_.jpg\n",
      "Successfully embedded asos-dresses/dresses_6_.jpg\n",
      "Processing: asos-dresses/dresses_7_.jpg\n",
      "Successfully embedded asos-dresses/dresses_7_.jpg\n",
      "Saved embeddings to embeddings_asos.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>embedding</th>\n",
       "      <th>raw_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asos-tops/tops_43_.jpg</td>\n",
       "      <td>[-0.0986347496509552, 0.11231251060962677, 0.0...</td>\n",
       "      <td>[{'color': 'white', 'material': 'appears to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asos-tops/tops_14_.jpg</td>\n",
       "      <td>[-0.12911318242549896, 0.040842585265636444, 0...</td>\n",
       "      <td>[{'color': 'white', 'material': 'cotton jersey...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_path                                          embedding  \\\n",
       "0  asos-tops/tops_43_.jpg  [-0.0986347496509552, 0.11231251060962677, 0.0...   \n",
       "1  asos-tops/tops_14_.jpg  [-0.12911318242549896, 0.040842585265636444, 0...   \n",
       "\n",
       "                                      raw_attributes  \n",
       "0  [{'color': 'white', 'material': 'appears to be...  \n",
       "1  [{'color': 'white', 'material': 'cotton jersey...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import voyageai\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (API key)\n",
    "load_dotenv(override=True)\n",
    "VOYAGE_API_KEY = os.getenv(\"VOYAGE_API_KEY\")\n",
    "\n",
    "# Initialize Voyage client with API key\n",
    "vo = voyageai.Client(api_key=VOYAGE_API_KEY)\n",
    "\n",
    "def load_attribute_descriptions(json_file_path):\n",
    "    \"\"\"Load the attribute descriptions from a JSON file.\"\"\"\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def prepare_text_for_embedding(attribute_list):\n",
    "    \"\"\"Convert attribute dictionary list to a single text string for embedding.\"\"\"\n",
    "    text_parts = []\n",
    "    \n",
    "    for attr_dict in attribute_list:\n",
    "        attribute = attr_dict.get('attribute', 'unknown')\n",
    "        text_parts.append(f\"Attribute: {attribute}\")\n",
    "        \n",
    "        # Add all other fields\n",
    "        for key, value in attr_dict.items():\n",
    "            if key != 'attribute' and key != 'error':\n",
    "                text_parts.append(f\"{key}: {value}\")\n",
    "        \n",
    "        text_parts.append(\"---\")  # Separator between attributes\n",
    "    \n",
    "    return \" \".join(text_parts)\n",
    "\n",
    "def embed_fashion_descriptions(json_file_path, output_file=\"embeddings_asos.csv\"):\n",
    "    \"\"\"Generate embeddings for each fashion item's full attribute description.\"\"\"\n",
    "    # Load the attribute descriptions\n",
    "    descriptions = load_attribute_descriptions(json_file_path)\n",
    "    \n",
    "    # Prepare DataFrame to store results\n",
    "    results = []\n",
    "    \n",
    "    # Process each image path\n",
    "    for image_path, attributes in descriptions.items():\n",
    "        print(f\"Processing: {image_path}\")\n",
    "        \n",
    "        # Convert the list of attribute dictionaries to a single text\n",
    "        full_description = prepare_text_for_embedding(attributes)\n",
    "        \n",
    "        try:\n",
    "            # Generate embedding for the entire dictionary as one text\n",
    "            embedding_result = vo.embed(\n",
    "                texts=[full_description],\n",
    "                model=\"voyage-3-large\",\n",
    "                input_type=\"document\",\n",
    "                output_dimension=256,\n",
    "                output_dtype=\"float\"\n",
    "            )\n",
    "            \n",
    "            # Store the result\n",
    "            results.append({\n",
    "                'image_path': image_path,\n",
    "                'embedding': embedding_result.embeddings[0],\n",
    "                'raw_attributes': attributes  # Store original attributes for reference\n",
    "            })\n",
    "            \n",
    "            print(f\"Successfully embedded {image_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding {image_path}: {e}\")\n",
    "        \n",
    "        # Add a small delay to respect rate limits\n",
    "        time.sleep(3)\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV (embeddings will be stored as strings)\n",
    "    df_to_save = df.copy()\n",
    "    df_to_save['embedding'] = df_to_save['embedding'].apply(lambda x: ','.join(map(str, x)))\n",
    "    df_to_save['raw_attributes'] = df_to_save['raw_attributes'].apply(json.dumps)\n",
    "    df_to_save.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Saved embeddings to {output_file}\")\n",
    "    return df\n",
    "\n",
    "# Function to search similar items using the embeddings\n",
    "def find_similar_fashion_items(df, query_image_path=None, query_text=None, top_n=5):\n",
    "    \"\"\"Find similar fashion items based on embeddings similarity.\"\"\"\n",
    "    if query_image_path is not None and query_image_path in df['image_path'].values:\n",
    "        # Get the embedding for the query image\n",
    "        query_embedding = df[df['image_path'] == query_image_path]['embedding'].iloc[0]\n",
    "    elif query_text is not None:\n",
    "        # Generate embedding for the query text\n",
    "        try:\n",
    "            query_result = vo.embed(\n",
    "                texts=[query_text],\n",
    "                model=\"voyage-3-large\",\n",
    "                input_type=\"document\",\n",
    "                output_dimension=256,\n",
    "                output_dtype=\"float\"\n",
    "            )\n",
    "            query_embedding = query_result.embeddings[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embedding for query text: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Either query_image_path or query_text must be provided\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate similarity scores\n",
    "    df['similarity'] = df['embedding'].apply(\n",
    "        lambda emb: sum(a*b for a, b in zip(emb, query_embedding)) / \n",
    "        (sum(a*a for a in emb)**0.5 * sum(b*b for b in query_embedding)**0.5)\n",
    "    )\n",
    "    \n",
    "    # Sort by similarity and return top matches\n",
    "    return df.sort_values('similarity', ascending=False).head(top_n)\n",
    "\n",
    "# Example usage in a Jupyter notebook\n",
    "# Run this in a cell\n",
    "\n",
    "# Load and embed fashion descriptions\n",
    "json_file_path = \"anthropic_asos_descriptions.json\"\n",
    "embeddings_asos_df = embed_fashion_descriptions(json_file_path)\n",
    "\n",
    "embeddings_asos_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: user/IMG_7394.JPG\n",
      "Successfully embedded user/IMG_7394.JPG\n",
      "Processing: user/IMG_7344.JPG\n",
      "Successfully embedded user/IMG_7344.JPG\n",
      "Processing: user/IMG_7268.JPG\n",
      "Successfully embedded user/IMG_7268.JPG\n",
      "Processing: user/IMG_7446.JPG\n",
      "Successfully embedded user/IMG_7446.JPG\n",
      "Processing: user/IMG_7453.JPG\n",
      "Successfully embedded user/IMG_7453.JPG\n",
      "Processing: user/IMG_7336.JPG\n",
      "Successfully embedded user/IMG_7336.JPG\n",
      "Processing: user/IMG_7503.JPG\n",
      "Successfully embedded user/IMG_7503.JPG\n",
      "Processing: user/IMG_7567.JPG\n",
      "Successfully embedded user/IMG_7567.JPG\n",
      "Saved embeddings to embeddings_user.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>embedding</th>\n",
       "      <th>raw_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user/IMG_7394.JPG</td>\n",
       "      <td>[-0.05037498474121094, 0.041566699743270874, 0...</td>\n",
       "      <td>[{'color': 'black', 'material': 'knit/stretch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user/IMG_7344.JPG</td>\n",
       "      <td>[-0.06044689193367958, 0.05194960534572601, 0....</td>\n",
       "      <td>[{'color': 'black', 'material': 'likely nylon/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_path                                          embedding  \\\n",
       "0  user/IMG_7394.JPG  [-0.05037498474121094, 0.041566699743270874, 0...   \n",
       "1  user/IMG_7344.JPG  [-0.06044689193367958, 0.05194960534572601, 0....   \n",
       "\n",
       "                                      raw_attributes  \n",
       "0  [{'color': 'black', 'material': 'knit/stretch ...  \n",
       "1  [{'color': 'black', 'material': 'likely nylon/...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_path = \"anthropic_user_descriptions.json\"\n",
    "embeddings_user_df = embed_fashion_descriptions(json_file_path, output_file=\"embeddings_user.csv\")\n",
    "\n",
    "embeddings_user_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
